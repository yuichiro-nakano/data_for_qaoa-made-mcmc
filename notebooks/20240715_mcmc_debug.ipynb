{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMCコードデバッグ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ising_model as ising\n",
    "import made\n",
    "import mcmc_function as mcmc\n",
    "import QAOA_function as qaoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMCと乱数の関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1514\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 2.2670482036304227e-09, 0)\n",
      "(array([-1,  1, -1,  1, -1,  1, -1,  1, -1,  1]), 1.0, 1)\n",
      "(array([-1,  1,  1,  1,  1,  1,  1, -1, -1, -1]), 1.0, 1)\n",
      "(array([-1, -1, -1,  1, -1, -1, -1,  1, -1, -1]), 1.0, 1)\n",
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 5.3347866206270535e-08, 0)\n",
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 9.545109307616367e-05, 0)\n",
      "(array([ 1,  1, -1, -1,  1, -1, -1, -1,  1,  1]), 1.0, 1)\n",
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 1.2833376627053181e-11, 0)\n",
      "(array([ 1, -1, -1, -1,  1,  1,  1, -1,  1,  1]), 1.0, 1)\n",
      "(array([-1, -1,  1,  1,  1,  1,  1,  1,  1,  1]), 1.0, 1)\n"
     ]
    }
   ],
   "source": [
    "n_spin = 10\n",
    "instance = ising.Ising_model(n_spin, rng, type='SK')\n",
    "beta = 10.0\n",
    "\n",
    "spin = ising.number_to_spin(0, n_spin)\n",
    "for i in range(10):\n",
    "\tprint(mcmc.uniform_update(spin, instance, beta, rng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル予測の部分について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs: np.ndarray):\n",
    "    n = model.nin\n",
    "    \n",
    "    # convert ndarray to torch.tensor\n",
    "    inputs_th = torch.from_numpy(inputs.copy()).to(dtype=torch.float32)\n",
    "    print(inputs_th.size())\n",
    "    \n",
    "    # apply model and sampling\n",
    "    logits = model(inputs_th)\n",
    "    outputs_th = torch.bernoulli(torch.sigmoid(logits))\n",
    "    print(outputs_th.size())\n",
    "    outputs = outputs_th.detach().numpy()\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -4.570202\n",
      "         Iterations: 30\n",
      "         Function evaluations: 618\n",
      "         Gradient evaluations: 56\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m traindata, testdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(dataset\u001b[38;5;241m=\u001b[39mopt_qaoa_data_nd, lengths\u001b[38;5;241m=\u001b[39m[n_test, n_samples\u001b[38;5;241m-\u001b[39mn_test])\n\u001b[1;32m     41\u001b[0m trainset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(traindata, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m testset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(testdata, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m hidden_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     45\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn_spin\n",
      "File \u001b[0;32m/opt/anaconda3/envs/quantum/lib/python3.11/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/quantum/lib/python3.11/site-packages/torch/utils/data/sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "n_spin = 6\n",
    "instance = ising.Ising_model(n_spin, rng, type='SK')\n",
    "\n",
    "# setting\n",
    "prob_hamiltonian = instance.get_hamiltonian()\n",
    "mixer_hamiltonian = qaoa.generate_X_mixer(n_spin)\n",
    "n_layers = 5\n",
    "qaoa_ansatz = qaoa.QAOA_ansatz(prob_hamiltonian, mixer_hamiltonian, n_layers)\n",
    "\n",
    "def cost(para):\n",
    "    return qaoa.cost_QAOA(prob_hamiltonian, qaoa_ansatz, para)\n",
    "\n",
    "def callback(para):\n",
    "    para_history.append(para)\n",
    "    cost_history.append(cost(para))\n",
    "\n",
    "# running QAOA\n",
    "#init_para = [rng.uniform(0, 2*np.pi) for i in range(2*n_layers)]\n",
    "init_para = [0.2705, -0.5899, 0.4803, -0.4492, 0.5074, -0.3559, 0.5646, -0.2643, 0.6397, -0.1291] #文献におけるSKmodelに対するQAOA(p=5)の固定角\n",
    "para_history = [init_para]\n",
    "cost_history = [cost(init_para)]\n",
    "\n",
    "method = \"BFGS\"\n",
    "options = {\"disp\": True, \"maxiter\": 200, \"gtol\": 1e-6}\n",
    "opt = scipy.optimize.minimize(cost, init_para, \n",
    "                              method=method,\n",
    "                              callback=callback,\n",
    "                              options=options)\n",
    "\n",
    "opt_para = para_history[-1]\n",
    "\n",
    "# sampling QAOA outputs\n",
    "n_samples = 2**6\n",
    "opt_qaoa_data_idx = qaoa.sampling_QAOA(qaoa_ansatz, para_history[-1], n_samples*10) # optimize parameter\n",
    "opt_qaoa_data_nd = np.array([qaoa.number_to_binary(opt_qaoa_data_idx[i], n_spin) for i in range(n_samples)], dtype='float32') # MADEモデルのコードが重み行列をfloat32で記述しているため、データもfloat32に明示的に指定する！\n",
    "\n",
    "n_data = 100\n",
    "n_test = int(0.8*n_data)\n",
    "\n",
    "traindata, testdata = torch.utils.data.random_split(dataset=opt_qaoa_data_nd, lengths=[n_test, n_samples-n_test])\n",
    "trainset = torch.utils.data.DataLoader(traindata, batch_size=8, shuffle=False)\n",
    "testset = torch.utils.data.DataLoader(testdata, batch_size=8, shuffle=True)\n",
    "\n",
    "hidden_layers = 2\n",
    "hidden_size = 2*n_spin\n",
    "hidden_list = [hidden_size for i in range(hidden_layers)]\n",
    "model = made.MADE(n_spin, hidden_list, n_spin, num_masks=1, natural_ordering=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=45, gamma=0.1)\n",
    "\n",
    "n_epochs = 30\n",
    "train_loss, test_loss = made.run_train(model, trainset, testset, n_epochs, opt, scheduler, seed)\n",
    "\n",
    "inputs = np.array([made.number_to_binary(rng.integers(0, 2**n_spin), n_spin) for i in range(n_samples*10)])\n",
    "qaoa_pred_data_nd = made.predict(model, inputs)\n",
    "\n",
    "qaoa_hist = np.histogram(opt_qaoa_data_idx, bins=np.arange(2**n_spin+1))\n",
    "\n",
    "beta = 2.0\n",
    "min_energy = ising.min_exact_spin_energy(instance)\n",
    "boltzmann_prob = ising.spin_boltzmann_distribution(instance, beta)\n",
    "boltzmann_prob_sort = np.sort(boltzmann_prob)[::-1]\n",
    "\n",
    "all_inputs = np.array([made.number_to_binary(i, n_spin) for i in range(2**n_spin)])\n",
    "pred_prob = made.compute_log_prob(model, all_inputs)\n",
    "pred_prob = np.exp(pred_prob) * n_samples * 10\n",
    "\n",
    "print(np.sum(qaoa_hist[0]))\n",
    "\n",
    "n_top = 16\n",
    "sort_idx = np.argsort(boltzmann_prob)[::-1]\n",
    "fig3_3, ax3_3 = plt.subplots(figsize=(8,4), dpi=200)\n",
    "#ax3_3.bar(np.arange(n_top), qaoa_hist[0][sort_idx[0:n_top]], color='red', alpha=0.5, label='MADE sampling')\n",
    "#ax3_3.bar(np.arange(n_top), pred_prob[sort_idx[0:n_top]], color='blue', alpha=0.5, label='MADE prob')\n",
    "ax3_3.bar(np.arange(2**n_spin), qaoa_hist[0], color='red', alpha=0.5, label='MADE sampling')\n",
    "ax3_3.bar(np.arange(2**n_spin), pred_prob, color='blue', alpha=0.5, label='MADE prob')\n",
    "ax3_3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1.]]\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "arr = rng.integers(2, size=(10,5)).astype(dtype=np.float32)\n",
    "print(arr)\n",
    "print(arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詳細釣り合いが満たされているかの確認"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
